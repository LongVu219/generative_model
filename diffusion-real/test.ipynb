{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from data_process import *\n",
    "\n",
    "# train_loader, test_loader = load_mnist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num params diffusion:  62248577\n",
      "Num params classifier:  11173386\n"
     ]
    }
   ],
   "source": [
    "from model import *\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = 'cuda'\n",
    "model_diff = SimpleUnet().to(device)\n",
    "print(\"Num params diffusion: \", sum(p.numel() for p in model_diff.parameters()))\n",
    "model_path = '/home/longvv/generative_model/models/diffusion_mnist_fixed.pth'\n",
    "model_diff.load_state_dict(torch.load(model_path, weights_only=True))\n",
    "\n",
    "from torchvision import models\n",
    "model_cls = models.resnet18()\n",
    "model_cls.conv1 = nn.Conv2d(\n",
    "    in_channels=2,\n",
    "    out_channels=64,\n",
    "    kernel_size=3,\n",
    "    stride=1,\n",
    "    padding=1,\n",
    "    bias=False\n",
    ")\n",
    "model_cls.maxpool = nn.Identity()\n",
    "model_cls.fc = nn.Linear(in_features=512, out_features=10, bias=True)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_cls = model_cls.to(device)\n",
    "print(\"Num params classifier: \", sum(p.numel() for p in model_cls.parameters()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 500\n",
    "start = 0.0001\n",
    "end = 0.05\n",
    "device = 'cuda'\n",
    "IMG_SIZE = 32\n",
    "BATCH_SIZE = 512\n",
    "\n",
    "betas = torch.linspace(start, end, T)\n",
    "alphas = 1. - betas\n",
    "alphas_cumprod = torch.cumprod(alphas, axis = 0)\n",
    "alphas_cumprod_prev = F.pad(alphas_cumprod[:-1], (1, 0), value=1.0)\n",
    "sqrt_recip_alphas = torch.sqrt(1.0 / alphas)\n",
    "sqrt_alphas_cumprod = torch.sqrt(alphas_cumprod)\n",
    "sqrt_one_minus_alphas_cumprod = torch.sqrt(1. - alphas_cumprod)\n",
    "posterior_variance = betas * (1. - alphas_cumprod_prev) / (1. - alphas_cumprod)\n",
    "\n",
    "def get_index_from_list(vals, t, x_shape):\n",
    "    batch_size = t.shape[0]\n",
    "    out = vals.gather(-1, t.cpu())\n",
    "    return out.reshape(batch_size, *((1,) * (len(x_shape) - 1))).to(t.device)\n",
    "\n",
    "def classifier_gradient(model, x_t, t, y, scale):\n",
    "    x_t = x_t.detach().clone().requires_grad_(True)\n",
    "    B, C, H, W = x_t.shape\n",
    "    timestep = (t.float() / T)\n",
    "    timestep = timestep.view(B, 1, 1, 1)\n",
    "    timestep = timestep.expand(B, 1, H, W).to(x_t.device)\n",
    "    classifier_input = torch.cat([x_t, timestep], dim=1)\n",
    "\n",
    "    model.eval()\n",
    "    logits = model(classifier_input)\n",
    "    log_probs = F.log_softmax(logits, dim=1)\n",
    "    log_prob_of_y = log_probs.gather(1, y.view(-1,1)).squeeze(1)\n",
    "    loss_for_grad = -log_prob_of_y.sum()  \n",
    "    model.zero_grad()\n",
    "    loss_for_grad.backward(retain_graph=True)\n",
    "\n",
    "    grad_log = -x_t.grad.detach()  \n",
    "\n",
    "    grad_scaled = scale * grad_log\n",
    "    return grad_scaled\n",
    "\n",
    "@torch.no_grad()\n",
    "def sample_timestep(model_diff, model_cls, x, t, y, scale):\n",
    "    \"\"\"\n",
    "    Calls the model to predict the noise in the image and returns \n",
    "    the denoised image. \n",
    "    Applies noise to this image, if we are not in the last step yet.\n",
    "    \"\"\"\n",
    "    betas_t = get_index_from_list(betas, t, x.shape)\n",
    "    sqrt_one_minus_alphas_cumprod_t = get_index_from_list(\n",
    "        sqrt_one_minus_alphas_cumprod, t, x.shape\n",
    "    )\n",
    "    sqrt_recip_alphas_t = get_index_from_list(sqrt_recip_alphas, t, x.shape)\n",
    "    \n",
    "    # Call model (current image - noise prediction)\n",
    "    model_mean = sqrt_recip_alphas_t * (\n",
    "        x - betas_t * model_diff(x, t) / sqrt_one_minus_alphas_cumprod_t\n",
    "    )\n",
    "    posterior_variance_t = get_index_from_list(posterior_variance, t, x.shape)\n",
    "    \n",
    "    if t == 0:\n",
    "        # As pointed out by Luis Pereira (see YouTube comment)\n",
    "        # The t's are offset from the t's in the paper\n",
    "        return model_mean\n",
    "    else:\n",
    "        noise = torch.randn_like(x)\n",
    "        cls_grad = classifier_gradient(model_cls, x, t, y, scale)\n",
    "        model_mean = model_mean + torch.sqrt(posterior_variance_t) * noise  * scale * cls_grad\n",
    "        return model_mean + torch.sqrt(posterior_variance_t) * noise\n",
    "\n",
    "def show_images(img_name, dataset, num_samples=10, cols=5, save = True):\n",
    "    \"\"\" Plots some samples from the dataset \"\"\"\n",
    "    plt.figure(figsize=(15,15)) \n",
    "    for i, img in enumerate(dataset):\n",
    "        img = img.detach().to('cpu')\n",
    "        if i == num_samples:\n",
    "            break\n",
    "        plt.subplot(int(num_samples/cols) + 1, cols, i + 1)\n",
    "        \n",
    "        #for mnist image only, if u need colored stuff, stick with 'convert_to_image' function in source code \n",
    "        plt.imshow(img.squeeze(dim=0), cmap='gray')\n",
    "    \n",
    "    if (save == True):\n",
    "        name = 'output_' + str(img_name) + '.png'\n",
    "        plt.savefig('/home/longvv/generative_model/diffusion-real/result/' + name)\n",
    "    plt.show()\n",
    "\n",
    "IMG_SIZE = 32\n",
    "@torch.no_grad()\n",
    "def classifier_guidance(model_diff, model_cls, y, scale):\n",
    "    img_name = 'test' + y + '.png'\n",
    "    img_size = IMG_SIZE\n",
    "    img = torch.randn((1, 1, img_size, img_size), device=device)\n",
    "    img_set = []\n",
    "    num_images = 10\n",
    "    stepsize = int(T/num_images)\n",
    "\n",
    "    for i in range(0,T)[::-1]:\n",
    "        t = torch.full((1,), i, device=device, dtype=torch.long)\n",
    "        img = sample_timestep(model_diff, model_cls, img, t, y, scale)\n",
    "        # Edit: This is to maintain the natural range of the distribution\n",
    "        #img = torch.clamp(img, -1.0, 1.0)\n",
    "        if i % stepsize == 0:\n",
    "            img_set.append(img.squeeze(dim = 0))\n",
    "            \n",
    "    show_images(img_name, img_set, save = True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
