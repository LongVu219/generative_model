/home/longvv/anaconda3/lib/python3.10/site-packages/torch/nn/modules/conv.py:952: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)
  return F.conv_transpose2d(
/home/longvv/anaconda3/lib/python3.10/site-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
Epoch 0 | step 000 Loss: 1.031508445739746
Epoch 0 | step 030 Loss: 0.1332177221775055
Epoch 0 | step 060 Loss: 0.06977413594722748
Epoch 0 | step 090 Loss: 0.045864954590797424
/home/longvv/anaconda3/lib/python3.10/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)
  return F.conv2d(input, weight, bias, self.stride,
Test Loss : 0.04729551244527101
------------------------------
Epoch 1 | step 000 Loss: 0.04375927150249481
Epoch 1 | step 030 Loss: 0.04352652281522751
Epoch 1 | step 060 Loss: 0.03811805695295334
Epoch 1 | step 090 Loss: 0.03618218004703522
Test Loss : 0.03960002232342959
------------------------------
Epoch 2 | step 000 Loss: 0.03834120184183121
Epoch 2 | step 030 Loss: 0.03768082708120346
Epoch 2 | step 060 Loss: 0.02771195024251938
Epoch 2 | step 090 Loss: 0.030666533857584
Test Loss : 0.03272428698837757
------------------------------
Epoch 3 | step 000 Loss: 0.03538942709565163
Epoch 3 | step 030 Loss: 0.03077531047165394
Epoch 3 | step 060 Loss: 0.025179438292980194
Epoch 3 | step 090 Loss: 0.03190988302230835
Test Loss : 0.03094947887584567
------------------------------
Epoch 4 | step 000 Loss: 0.02937958762049675
Epoch 4 | step 030 Loss: 0.02775796875357628
Epoch 4 | step 060 Loss: 0.027384288609027863
Epoch 4 | step 090 Loss: 0.024105409160256386
Test Loss : 0.03036139430478215
------------------------------
Epoch 5 | step 000 Loss: 0.026499398052692413
Epoch 5 | step 030 Loss: 0.024792157113552094
Epoch 5 | step 060 Loss: 0.025113027542829514
Epoch 5 | step 090 Loss: 0.028005193918943405
Test Loss : 0.027344806399196387
------------------------------
Epoch 6 | step 000 Loss: 0.024849655106663704
Epoch 6 | step 030 Loss: 0.027541978284716606
Epoch 6 | step 060 Loss: 0.02688959799706936
Epoch 6 | step 090 Loss: 0.026212943717837334
Test Loss : 0.027295449655503033
------------------------------
Epoch 7 | step 000 Loss: 0.026845356449484825
Epoch 7 | step 030 Loss: 0.025231335312128067
Epoch 7 | step 060 Loss: 0.021764196455478668
Epoch 7 | step 090 Loss: 0.024494020268321037
Test Loss : 0.027433844283223152
------------------------------
Epoch 8 | step 000 Loss: 0.029944714158773422
Epoch 8 | step 030 Loss: 0.025887951254844666
Epoch 8 | step 060 Loss: 0.023314978927373886
Epoch 8 | step 090 Loss: 0.028858162462711334
Test Loss : 0.026613334752619268
------------------------------
Epoch 9 | step 000 Loss: 0.02446301467716694
Epoch 9 | step 030 Loss: 0.027125775814056396
Epoch 9 | step 060 Loss: 0.02725892886519432
Epoch 9 | step 090 Loss: 0.02639087475836277
Test Loss : 0.028134598676115275
------------------------------
Epoch 10 | step 000 Loss: 0.025906719267368317
Epoch 10 | step 030 Loss: 0.02527780272066593
Epoch 10 | step 060 Loss: 0.022353800013661385
Epoch 10 | step 090 Loss: 0.025316480547189713
Test Loss : 0.02447642106562853
------------------------------
Epoch 11 | step 000 Loss: 0.024254003539681435
Epoch 11 | step 030 Loss: 0.027522340416908264
Epoch 11 | step 060 Loss: 0.024258723482489586
Epoch 11 | step 090 Loss: 0.02472248300909996
Test Loss : 0.02797346543520689
------------------------------
Epoch 12 | step 000 Loss: 0.025853954255580902
Epoch 12 | step 030 Loss: 0.0239945687353611
Epoch 12 | step 060 Loss: 0.02303651161491871
Epoch 12 | step 090 Loss: 0.02399357222020626
Test Loss : 0.025286656245589255
------------------------------
Epoch 13 | step 000 Loss: 0.027255117893218994
Epoch 13 | step 030 Loss: 0.024798836559057236
Epoch 13 | step 060 Loss: 0.023701872676610947
Epoch 13 | step 090 Loss: 0.02527656778693199
Test Loss : 0.02368849404156208
------------------------------
Epoch 14 | step 000 Loss: 0.024159319698810577
Epoch 14 | step 030 Loss: 0.023312930017709732
Epoch 14 | step 060 Loss: 0.023940518498420715
Epoch 14 | step 090 Loss: 0.02133752405643463
Test Loss : 0.023697348590940238
------------------------------
Epoch 15 | step 000 Loss: 0.026411771774291992
Epoch 15 | step 030 Loss: 0.02386072836816311
Epoch 15 | step 060 Loss: 0.025515062734484673
Epoch 15 | step 090 Loss: 0.024157337844371796
Test Loss : 0.023732085805386306
------------------------------
Epoch 16 | step 000 Loss: 0.023837247863411903
Epoch 16 | step 030 Loss: 0.02094566822052002
Epoch 16 | step 060 Loss: 0.02298259362578392
Epoch 16 | step 090 Loss: 0.021962258964776993
Test Loss : 0.02297948198392987
------------------------------
Epoch 17 | step 000 Loss: 0.022077850997447968
Epoch 17 | step 030 Loss: 0.02130850777029991
Epoch 17 | step 060 Loss: 0.027067814022302628
Epoch 17 | step 090 Loss: 0.021797221153974533
Test Loss : 0.02338999044150114
------------------------------
Epoch 18 | step 000 Loss: 0.023922836408019066
Epoch 18 | step 030 Loss: 0.021425539627671242
Epoch 18 | step 060 Loss: 0.024776356294751167
Epoch 18 | step 090 Loss: 0.019781943410634995
Test Loss : 0.023325055837631226
------------------------------
Epoch 19 | step 000 Loss: 0.02521638385951519
Epoch 19 | step 030 Loss: 0.02325766533613205
Epoch 19 | step 060 Loss: 0.024978984147310257
Epoch 19 | step 090 Loss: 0.021320782601833344
Test Loss : 0.024167681857943536
------------------------------
Epoch 20 | step 000 Loss: 0.02299869805574417
Epoch 20 | step 030 Loss: 0.023730259388685226
Epoch 20 | step 060 Loss: 0.023338623344898224
Epoch 20 | step 090 Loss: 0.025943202897906303
Test Loss : 0.02451641093939543
------------------------------
Epoch 21 | step 000 Loss: 0.0240781269967556
Epoch 21 | step 030 Loss: 0.021306518465280533
Epoch 21 | step 060 Loss: 0.02532651461660862
Epoch 21 | step 090 Loss: 0.023219972848892212
Test Loss : 0.02340748580172658
------------------------------
Epoch 22 | step 000 Loss: 0.024845866486430168
Epoch 22 | step 030 Loss: 0.02035338804125786
Epoch 22 | step 060 Loss: 0.023192759603261948
Epoch 22 | step 090 Loss: 0.02207900397479534
Test Loss : 0.022428960911929606
------------------------------
Epoch 23 | step 000 Loss: 0.02022099867463112
Epoch 23 | step 030 Loss: 0.021259868517518044
Epoch 23 | step 060 Loss: 0.02093338593840599
Epoch 23 | step 090 Loss: 0.02347445860505104
Test Loss : 0.02271765023469925
------------------------------
Epoch 24 | step 000 Loss: 0.025002488866448402
Epoch 24 | step 030 Loss: 0.020111719146370888
Epoch 24 | step 060 Loss: 0.02079204097390175
Epoch 24 | step 090 Loss: 0.02204003930091858
Test Loss : 0.02421257719397545
------------------------------
Epoch 25 | step 000 Loss: 0.021254025399684906
Epoch 25 | step 030 Loss: 0.021927349269390106
Epoch 25 | step 060 Loss: 0.01894180290400982
Epoch 25 | step 090 Loss: 0.023521455004811287
Test Loss : 0.023260472062975168
------------------------------
Epoch 26 | step 000 Loss: 0.02097177691757679
Epoch 26 | step 030 Loss: 0.023729192093014717
Epoch 26 | step 060 Loss: 0.022719208151102066
Epoch 26 | step 090 Loss: 0.020574595779180527
Test Loss : 0.024044372607022524
------------------------------
Epoch 27 | step 000 Loss: 0.023923400789499283
Epoch 27 | step 030 Loss: 0.023129429668188095
Epoch 27 | step 060 Loss: 0.022242480888962746
Epoch 27 | step 090 Loss: 0.020072489976882935
Test Loss : 0.022714279219508172
------------------------------
Epoch 28 | step 000 Loss: 0.022368894889950752
Epoch 28 | step 030 Loss: 0.022529389709234238
Epoch 28 | step 060 Loss: 0.019954966381192207
Epoch 28 | step 090 Loss: 0.022398900240659714
Test Loss : 0.02248469032347202
------------------------------
Epoch 29 | step 000 Loss: 0.0242539644241333
Epoch 29 | step 030 Loss: 0.022330649197101593
Epoch 29 | step 060 Loss: 0.024147287011146545
Epoch 29 | step 090 Loss: 0.01942521519958973
Test Loss : 0.022025971859693527
------------------------------
Epoch 30 | step 000 Loss: 0.017253335565328598
Epoch 30 | step 030 Loss: 0.022893143817782402
Epoch 30 | step 060 Loss: 0.018586017191410065
Epoch 30 | step 090 Loss: 0.020935948938131332
Test Loss : 0.02193727707490325
------------------------------
Epoch 31 | step 000 Loss: 0.02023310586810112
Epoch 31 | step 030 Loss: 0.020138602703809738
Epoch 31 | step 060 Loss: 0.02120261639356613
Epoch 31 | step 090 Loss: 0.020746976137161255
Test Loss : 0.021712460089474916
------------------------------
Epoch 32 | step 000 Loss: 0.021166114136576653
Epoch 32 | step 030 Loss: 0.0190866831690073
Epoch 32 | step 060 Loss: 0.021396169438958168
Epoch 32 | step 090 Loss: 0.020340535789728165
Test Loss : 0.0226466809399426
------------------------------
Epoch 33 | step 000 Loss: 0.022362545132637024
Epoch 33 | step 030 Loss: 0.021440476179122925
Epoch 33 | step 060 Loss: 0.02006470039486885
Epoch 33 | step 090 Loss: 0.021127531304955482
Test Loss : 0.02181356307119131
------------------------------
Epoch 34 | step 000 Loss: 0.024485327303409576
Epoch 34 | step 030 Loss: 0.020688103511929512
Epoch 34 | step 060 Loss: 0.022480711340904236
Epoch 34 | step 090 Loss: 0.018570061773061752
Test Loss : 0.02066284455358982
------------------------------
Epoch 35 | step 000 Loss: 0.02170373499393463
Epoch 35 | step 030 Loss: 0.023722613230347633
Epoch 35 | step 060 Loss: 0.02134525403380394
Epoch 35 | step 090 Loss: 0.020017383620142937
Test Loss : 0.02128845062106848
------------------------------
Epoch 36 | step 000 Loss: 0.019802171736955643
Epoch 36 | step 030 Loss: 0.019645266234874725
Epoch 36 | step 060 Loss: 0.01898181438446045
Epoch 36 | step 090 Loss: 0.018801435828208923
Test Loss : 0.022113209031522273
------------------------------
Epoch 37 | step 000 Loss: 0.021959420293569565
Epoch 37 | step 030 Loss: 0.02056644856929779
Epoch 37 | step 060 Loss: 0.020277144387364388
Epoch 37 | step 090 Loss: 0.0233890563249588
Test Loss : 0.02157042920589447
------------------------------
Epoch 38 | step 000 Loss: 0.020271066576242447
Epoch 38 | step 030 Loss: 0.02175767347216606
Epoch 38 | step 060 Loss: 0.021493658423423767
Epoch 38 | step 090 Loss: 0.02097567543387413
Test Loss : 0.022738689463585614
------------------------------
Epoch 39 | step 000 Loss: 0.02195315808057785
Epoch 39 | step 030 Loss: 0.02320687845349312
Epoch 39 | step 060 Loss: 0.021908465772867203
Epoch 39 | step 090 Loss: 0.020893266424536705
Test Loss : 0.021661156602203847
------------------------------
Epoch 40 | step 000 Loss: 0.02265721559524536
Epoch 40 | step 030 Loss: 0.01763475313782692
Epoch 40 | step 060 Loss: 0.01882004551589489
Epoch 40 | step 090 Loss: 0.020668786019086838
Test Loss : 0.02127118781208992
------------------------------
Epoch 41 | step 000 Loss: 0.023666270077228546
Epoch 41 | step 030 Loss: 0.020415261387825012
Epoch 41 | step 060 Loss: 0.0184960775077343
Epoch 41 | step 090 Loss: 0.01902153342962265
Test Loss : 0.022544812131673097
------------------------------
Epoch 42 | step 000 Loss: 0.019748317077755928
Epoch 42 | step 030 Loss: 0.02257705107331276
Epoch 42 | step 060 Loss: 0.020855167880654335
Epoch 42 | step 090 Loss: 0.021378347650170326
Test Loss : 0.021212234906852246
------------------------------
Epoch 43 | step 000 Loss: 0.020445728674530983
Epoch 43 | step 030 Loss: 0.02207084186375141
Epoch 43 | step 060 Loss: 0.020718688145279884
Epoch 43 | step 090 Loss: 0.021889518946409225
Test Loss : 0.02139094192534685
------------------------------
Epoch 44 | step 000 Loss: 0.021354254335165024
Epoch 44 | step 030 Loss: 0.02019437775015831
Epoch 44 | step 060 Loss: 0.02307668700814247
Epoch 44 | step 090 Loss: 0.022093813866376877
Test Loss : 0.020812995731830597
------------------------------
Traceback (most recent call last):
  File "/home/longvv/generative_model/diffusion-real/train.py", line 175, in <module>
    torch.save(model.state_dict(), model_path)
  File "/home/longvv/anaconda3/lib/python3.10/site-packages/torch/serialization.py", line 627, in save
    with _open_zipfile_writer(f) as opened_zipfile:
  File "/home/longvv/anaconda3/lib/python3.10/site-packages/torch/serialization.py", line 501, in _open_zipfile_writer
    return container(name_or_buffer)
  File "/home/longvv/anaconda3/lib/python3.10/site-packages/torch/serialization.py", line 472, in __init__
    super().__init__(torch._C.PyTorchFileWriter(self.name))
RuntimeError: Parent directory /home/dominhnhat/Classroom/generative_model/models does not exist.
